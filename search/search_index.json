{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Django REST Framework Pipeline Views pip install drf-pipeline-views Documentation : https://mrthearman.github.io/drf-pipeline-views/ Source Code : https://github.com/MrThearMan/drf-pipeline-views/ Inspired by a talk on The Clean Architecture in Python by Brandon Rhodes, drf-pipeline-views aims to simplify writing testable API endpoints with [Django REST framework][drf] using the Pipeline Design Pattern . The main idea behind the pipeline pattern is to process data in steps. Input from the previous step is passed to the next, resulting in a collection of \" data-in, data-out \" -functions. These functions can be easily unit tested, since none of the functions depend on the state of the objects in the other parts of the pipeline. Furthermore, IO can be separated into its own step, making the other parts of the logic simpler and faster to test by not having to mock or do any other special setup around the IO. This also means that the IO block, or in fact any other part of the application, can be replaced as long as the data flowing through the pipeline remains the same. Example Pipeline from pipeline_views import BasePipelineView from .my_serializers import InputSerializer , OutputSerializer from .my_validators import validator from .my_services import io_func , logging_func , integration_func class SomeView ( BasePipelineView ): pipelines = { \"GET\" : [ InputSerializer , validator , io_func , integration_func , logging_func , OutputSerializer , ], }","title":"Home"},{"location":"#django-rest-framework-pipeline-views","text":"pip install drf-pipeline-views Documentation : https://mrthearman.github.io/drf-pipeline-views/ Source Code : https://github.com/MrThearMan/drf-pipeline-views/ Inspired by a talk on The Clean Architecture in Python by Brandon Rhodes, drf-pipeline-views aims to simplify writing testable API endpoints with [Django REST framework][drf] using the Pipeline Design Pattern . The main idea behind the pipeline pattern is to process data in steps. Input from the previous step is passed to the next, resulting in a collection of \" data-in, data-out \" -functions. These functions can be easily unit tested, since none of the functions depend on the state of the objects in the other parts of the pipeline. Furthermore, IO can be separated into its own step, making the other parts of the logic simpler and faster to test by not having to mock or do any other special setup around the IO. This also means that the IO block, or in fact any other part of the application, can be replaced as long as the data flowing through the pipeline remains the same. Example Pipeline from pipeline_views import BasePipelineView from .my_serializers import InputSerializer , OutputSerializer from .my_validators import validator from .my_services import io_func , logging_func , integration_func class SomeView ( BasePipelineView ): pipelines = { \"GET\" : [ InputSerializer , validator , io_func , integration_func , logging_func , OutputSerializer , ], }","title":"Django REST Framework Pipeline Views"},{"location":"async/","text":"Async Logic Callables Pipeline logic callables can also be coroutines. The best part about coroutines is that they can be run in parallel. You parallel execution in a pipeline easily with a tuple, i.e., a parallel block . services.py async def async_step1 ( ... ): ... async def async_step2_1 ( ... ): ... async def async_step2_2 ( ... ): ... async def async_step3 ( ... ): ... views.py from pipeline_views import BasePipelineView from .services import async_step1 , async_step2_1 , async_step2_2 , async_step3 class SomeView ( BasePipelineView ): pipelines = { \"GET\" : [ async_step1 , ( async_step2_1 , async_step2_2 , ), async_step3 , ], } Now async_step2_1 and async_step2_2 will be executed in parallel, and will both receive all the arguments from async_step1 . async_step2_1 and async_step2_2 should return dictionaries like standard pipeline logic methods. async_step3 will then receive a union of the results of these coroutines. If the return dictionaries of the two coroutines have any common keys, the value from the coroutine defined last in the parallel block will be used. Return values from the callable before the parallel excecution can be passed to the next step after the parallel execution by setting ... (ellipses) in the tuple. If there are any common keys in this case, the values from the logic block will be prioritized. views.py from pipeline_views import BasePipelineView from .services import async_step1 , async_step2_1 , async_step2_2 , async_step3 class SomeView ( BasePipelineView ): pipelines = { \"GET\" : [ async_step1 , ( async_step2_1 , async_step2_2 , ... ), async_step3 , ], }","title":"Async Logic Callables"},{"location":"async/#async-logic-callables","text":"Pipeline logic callables can also be coroutines. The best part about coroutines is that they can be run in parallel. You parallel execution in a pipeline easily with a tuple, i.e., a parallel block . services.py async def async_step1 ( ... ): ... async def async_step2_1 ( ... ): ... async def async_step2_2 ( ... ): ... async def async_step3 ( ... ): ... views.py from pipeline_views import BasePipelineView from .services import async_step1 , async_step2_1 , async_step2_2 , async_step3 class SomeView ( BasePipelineView ): pipelines = { \"GET\" : [ async_step1 , ( async_step2_1 , async_step2_2 , ), async_step3 , ], } Now async_step2_1 and async_step2_2 will be executed in parallel, and will both receive all the arguments from async_step1 . async_step2_1 and async_step2_2 should return dictionaries like standard pipeline logic methods. async_step3 will then receive a union of the results of these coroutines. If the return dictionaries of the two coroutines have any common keys, the value from the coroutine defined last in the parallel block will be used. Return values from the callable before the parallel excecution can be passed to the next step after the parallel execution by setting ... (ellipses) in the tuple. If there are any common keys in this case, the values from the logic block will be prioritized. views.py from pipeline_views import BasePipelineView from .services import async_step1 , async_step2_1 , async_step2_2 , async_step3 class SomeView ( BasePipelineView ): pipelines = { \"GET\" : [ async_step1 , ( async_step2_1 , async_step2_2 , ... ), async_step3 , ], }","title":"Async Logic Callables"},{"location":"conditionals/","text":"Conditional logic paths Sometimes you might want to run different logic based on the output from the previous logic method. This can be accomplished with conditional logic paths. def step1 ( data ): if condition : return \"foo\" , data else : return \"bar\" , data class SomeView ( BasePipelineView ): pipelines = { \"GET\" : [ step1 , { \"foo\" : step2_1 , \"bar\" : step2_2 , }, ... ], } Notice that step1 returned a tuple of the data and key used to select the logic in the next step. Data should still be a dict, which matches the logic function's signature that the given key selects from the next step. Conditional paths also work inside logic blocks. You could also use conditionals to run only one method from a logic block, since it just uses __getitem__ to select the next logic method. def step1 ( data ): if condition : return 0 , data else : return 1 , data class SomeView ( BasePipelineView ): pipelines = { \"GET\" : [ step1 , [ block1_step1 , # run if condition is truthy block1_step2 , # run if condition is falsy ], ... ], }","title":"Conditional Logic Paths"},{"location":"conditionals/#conditional-logic-paths","text":"Sometimes you might want to run different logic based on the output from the previous logic method. This can be accomplished with conditional logic paths. def step1 ( data ): if condition : return \"foo\" , data else : return \"bar\" , data class SomeView ( BasePipelineView ): pipelines = { \"GET\" : [ step1 , { \"foo\" : step2_1 , \"bar\" : step2_2 , }, ... ], } Notice that step1 returned a tuple of the data and key used to select the logic in the next step. Data should still be a dict, which matches the logic function's signature that the given key selects from the next step. Conditional paths also work inside logic blocks. You could also use conditionals to run only one method from a logic block, since it just uses __getitem__ to select the next logic method. def step1 ( data ): if condition : return 0 , data else : return 1 , data class SomeView ( BasePipelineView ): pipelines = { \"GET\" : [ step1 , [ block1_step1 , # run if condition is truthy block1_step2 , # run if condition is falsy ], ... ], }","title":"Conditional logic paths"},{"location":"inference/","text":"Serializer inference Input serializer A pipeline can also be constructed without Serializers. class SomeView ( BasePipelineView ): pipelines = { \"GET\" : [ step1 , step2 , step3 , step4 , step5 , ], } BasePipelineView will try to infer an input serializer with the correct serializer fields, based on the type hints to the first function step1 . from rest_framework.fields import CharField , IntegerField from pipeline_views import MockSerializer # Callable def logic_callable ( name : str , age : int ): ... # Inferred Serializer class LogicCallableSerializer ( MockSerializer ): name = CharField () age = IntegerField () This is only used by the Django REST Framework Browsable API to create forms. MockSerializer makes sure the fields are only used for input and not validation. Output serializer Serializer inference can be extended to create output serializers a well. In this case, the last callable would be used ( step5 in this case), and the inference would be done based on it's output type. A TypedDict (or a list containing TypedDicts) should be used so that fields can be determined.","title":"Serializer Inference"},{"location":"inference/#serializer-inference","text":"","title":"Serializer inference"},{"location":"inference/#input-serializer","text":"A pipeline can also be constructed without Serializers. class SomeView ( BasePipelineView ): pipelines = { \"GET\" : [ step1 , step2 , step3 , step4 , step5 , ], } BasePipelineView will try to infer an input serializer with the correct serializer fields, based on the type hints to the first function step1 . from rest_framework.fields import CharField , IntegerField from pipeline_views import MockSerializer # Callable def logic_callable ( name : str , age : int ): ... # Inferred Serializer class LogicCallableSerializer ( MockSerializer ): name = CharField () age = IntegerField () This is only used by the Django REST Framework Browsable API to create forms. MockSerializer makes sure the fields are only used for input and not validation.","title":"Input serializer"},{"location":"inference/#output-serializer","text":"Serializer inference can be extended to create output serializers a well. In this case, the last callable would be used ( step5 in this case), and the inference would be done based on it's output type. A TypedDict (or a list containing TypedDicts) should be used so that fields can be determined.","title":"Output serializer"},{"location":"logic_blocks/","text":"Logic Blocks Pipeline logic, as well as serializers, can be grouped into blocks: class SomeView ( BasePipelineView ): pipelines = { \"GET\" : [ [ block1_step1 , block1_step2 , ], [ SerializerBlock2 , block2_step1 , block2_step2 , ], ], } These can be useful if you want to: Define and reuse a logic block in multiple pipelines. Separate related parts of the pipeline for clarity. Skip some parts of the logic under certain conditions, e.g., to return a cached result. Raising a NextLogicBlock exception within a logic block will exit the logic block with the data given to it. NextLogicBlock(**kwargs) , will output the given kwargs and, NextLogicBlock.with_output(output=...) , will output the given output, e.g., a list. from pipeline_views import NextLogicBlock def block1_step1 ( step1_input1 , step1_input2 ): if condition : raise NextLogicBlock ( step3_input1 =... , step3_input2 =... ) ... def block1_step2 ( step2_input1 , step2_input2 ): ... def block2_step1 ( step3_input1 , step3_input2 ): if condition : raise NextLogicBlock . with_output ( output =... ) ... def block2_step2 (): ... Logic blocks can be stacked recursively inside each other. In this case, NextLogicBlock will return to the parent logic block. class SomeView ( BasePipelineView ): pipelines = { \"GET\" : [ [ block1_step1 , [ block2_step1 , [ block3_step1 , [ ... ], ], ], ], ], } Although NextLogicBlock can be used on the base level of the pipeline, this should generally be avoided, keeping the justification for input and output serializers in mind.","title":"Logic Blocks"},{"location":"logic_blocks/#logic-blocks","text":"Pipeline logic, as well as serializers, can be grouped into blocks: class SomeView ( BasePipelineView ): pipelines = { \"GET\" : [ [ block1_step1 , block1_step2 , ], [ SerializerBlock2 , block2_step1 , block2_step2 , ], ], } These can be useful if you want to: Define and reuse a logic block in multiple pipelines. Separate related parts of the pipeline for clarity. Skip some parts of the logic under certain conditions, e.g., to return a cached result. Raising a NextLogicBlock exception within a logic block will exit the logic block with the data given to it. NextLogicBlock(**kwargs) , will output the given kwargs and, NextLogicBlock.with_output(output=...) , will output the given output, e.g., a list. from pipeline_views import NextLogicBlock def block1_step1 ( step1_input1 , step1_input2 ): if condition : raise NextLogicBlock ( step3_input1 =... , step3_input2 =... ) ... def block1_step2 ( step2_input1 , step2_input2 ): ... def block2_step1 ( step3_input1 , step3_input2 ): if condition : raise NextLogicBlock . with_output ( output =... ) ... def block2_step2 (): ... Logic blocks can be stacked recursively inside each other. In this case, NextLogicBlock will return to the parent logic block. class SomeView ( BasePipelineView ): pipelines = { \"GET\" : [ [ block1_step1 , [ block2_step1 , [ block3_step1 , [ ... ], ], ], ], ], } Although NextLogicBlock can be used on the base level of the pipeline, this should generally be avoided, keeping the justification for input and output serializers in mind.","title":"Logic Blocks"},{"location":"metadata/","text":"Metadata class Pipeline views include a metadata class that adds additional data to OPTIONS responses based on defined pipelines' Input and Output serializers. For example, a pipeline defined like this: class InputSerializer ( serializers . Serializer ): \"\"\"Example Input\"\"\" name = serializers . CharField ( help_text = \"Help\" ) age = serializers . IntegerField () class OutputSerializer ( serializers . Serializer ): \"\"\"Example Output\"\"\" email = serializers . EmailField ( help_text = \"Text\" ) age = serializers . IntegerField () class ExampleView ( BasePipelineView ): \"\"\"This is the description\"\"\" pipelines = { \"GET\" : [ InputSerializer , OutputSerializer , ], } ...will produce the following OPTIONS response: { \"name\" : \"Example\" , \"description\" : \"This is the description\" , \"renders\" : [ \"application/json\" , \"text/html\" ], \"parses\" : [ \"application/json\" , \"application/x-www-form-urlencoded\" , \"multipart/form-data\" ], \"actions\" : { \"GET\" : { \"input\" : { \"name\" : { \"type\" : \"string\" , \"required\" : true , \"help_text\" : \"Help\" }, \"age\" : { \"type\" : \"integer\" , \"required\" : true } }, \"output\" : { \"email\" : { \"type\" : \"email\" , \"required\" : true , \"help_text\" : \"Text\" }, \"age\" : { \"type\" : \"integer\" , \"required\" : true } } } } }","title":"Metadata"},{"location":"metadata/#metadata-class","text":"Pipeline views include a metadata class that adds additional data to OPTIONS responses based on defined pipelines' Input and Output serializers. For example, a pipeline defined like this: class InputSerializer ( serializers . Serializer ): \"\"\"Example Input\"\"\" name = serializers . CharField ( help_text = \"Help\" ) age = serializers . IntegerField () class OutputSerializer ( serializers . Serializer ): \"\"\"Example Output\"\"\" email = serializers . EmailField ( help_text = \"Text\" ) age = serializers . IntegerField () class ExampleView ( BasePipelineView ): \"\"\"This is the description\"\"\" pipelines = { \"GET\" : [ InputSerializer , OutputSerializer , ], } ...will produce the following OPTIONS response: { \"name\" : \"Example\" , \"description\" : \"This is the description\" , \"renders\" : [ \"application/json\" , \"text/html\" ], \"parses\" : [ \"application/json\" , \"application/x-www-form-urlencoded\" , \"multipart/form-data\" ], \"actions\" : { \"GET\" : { \"input\" : { \"name\" : { \"type\" : \"string\" , \"required\" : true , \"help_text\" : \"Help\" }, \"age\" : { \"type\" : \"integer\" , \"required\" : true } }, \"output\" : { \"email\" : { \"type\" : \"email\" , \"required\" : true , \"help_text\" : \"Text\" }, \"age\" : { \"type\" : \"integer\" , \"required\" : true } } } } }","title":"Metadata class"},{"location":"misc/","text":"Miscellaneous Modifying endpoint data If you wish to add data to a request, you can do that on the endpoint level by overriding process_request , or on the endpoint HTTP method level by overriding the specific method, like get . from rest_framework.exceptions import NotAuthenticated from rest_framework.authentication import get_authorization_header from pipeline_views import BasePipelineView from pipeline_views.utils import get_view_method class BasicView ( BasePipelineView ): pipelines = { \"GET\" : ... } def get ( self , request , * args , ** kwargs ): # Add language to every get request for this endpoint kwargs [ \"lang\" ] = request . LANGUAGE_CODE # View method needs to be added manually, since we defined `get` ourselves return get_view_method ( \"GET\" )( self , request , * args , ** kwargs ) def process_request ( self , data ): # Add authorization token to every http method data [ \"token\" ] = self . token_from_headers () return super () . process_request ( data = data ) def token_from_headers ( self ): auth_header = get_authorization_header ( self . request ) if not auth_header : raise NotAuthenticated ( \"You must be logged in for this endpoint.\" ) return auth_header . split ()[ 1 ] . decode () Translation The pipeline use a translate context manager to enable translations based on what the client is asking for. Use the LANGUAGES setting in django to define supported languages. Used language is determined from 1. a lang query parameter, or 2. request.LANGUAGE_CODE fetched from Accept-Language header (requires LocaleMiddleware ). Failing that, the tranlation falls back to the currently active language. Ignoring input parameters If some endpoint input parameter is not required in the pipeline logic, it can be ignored from the input data by placing it in a corresponding set on the endpoint level: from pipeline_views import BasePipelineView class BasicView ( BasePipelineView ): # Redefine ignored values ignored_get_params = { ... } # Extend the ignored values ignored_post_params = BasePipelineView . ignored_post_params | { ... } pipelines = { \"GET\" : ... , \"POST\" : ... } By default, the ignored keys include: \"format\" (used by DRF Rendered classes) and \"lang\" (used by @translate decorator) parameters. POST requests also ignore the csrfmiddlewaretoken given by forms.","title":"Miscellaneous"},{"location":"misc/#miscellaneous","text":"","title":"Miscellaneous"},{"location":"misc/#modifying-endpoint-data","text":"If you wish to add data to a request, you can do that on the endpoint level by overriding process_request , or on the endpoint HTTP method level by overriding the specific method, like get . from rest_framework.exceptions import NotAuthenticated from rest_framework.authentication import get_authorization_header from pipeline_views import BasePipelineView from pipeline_views.utils import get_view_method class BasicView ( BasePipelineView ): pipelines = { \"GET\" : ... } def get ( self , request , * args , ** kwargs ): # Add language to every get request for this endpoint kwargs [ \"lang\" ] = request . LANGUAGE_CODE # View method needs to be added manually, since we defined `get` ourselves return get_view_method ( \"GET\" )( self , request , * args , ** kwargs ) def process_request ( self , data ): # Add authorization token to every http method data [ \"token\" ] = self . token_from_headers () return super () . process_request ( data = data ) def token_from_headers ( self ): auth_header = get_authorization_header ( self . request ) if not auth_header : raise NotAuthenticated ( \"You must be logged in for this endpoint.\" ) return auth_header . split ()[ 1 ] . decode ()","title":"Modifying endpoint data"},{"location":"misc/#translation","text":"The pipeline use a translate context manager to enable translations based on what the client is asking for. Use the LANGUAGES setting in django to define supported languages. Used language is determined from 1. a lang query parameter, or 2. request.LANGUAGE_CODE fetched from Accept-Language header (requires LocaleMiddleware ). Failing that, the tranlation falls back to the currently active language.","title":"Translation"},{"location":"misc/#ignoring-input-parameters","text":"If some endpoint input parameter is not required in the pipeline logic, it can be ignored from the input data by placing it in a corresponding set on the endpoint level: from pipeline_views import BasePipelineView class BasicView ( BasePipelineView ): # Redefine ignored values ignored_get_params = { ... } # Extend the ignored values ignored_post_params = BasePipelineView . ignored_post_params | { ... } pipelines = { \"GET\" : ... , \"POST\" : ... } By default, the ignored keys include: \"format\" (used by DRF Rendered classes) and \"lang\" (used by @translate decorator) parameters. POST requests also ignore the csrfmiddlewaretoken given by forms.","title":"Ignoring input parameters"},{"location":"quickstart/","text":"Quickstart Example This will be a toy example, so the specific implementations details are not important here, rather the separation of logic. We are going to build a pipeline that takes product reviews from users, saves them to our database, contacts some outside system for recommendations based on the given review, and responds with the user's review and recommendation. It's a good idea to first define an InputSerializer, and an OutputSerializer that define the input and output of the pipeline respectively. This forces verification of the incoming and outcoming data, so that if something changes in the pipeline, or some unexpected values are produced, the endpoint will break instead of creating side effects in the application using the API. We'll also get better documentation in The Browsable API or any tool based on the OpenAPI specification, like Swagger. More about automatic documentation for pipeline views here . serializers.py from django.contrib.auth.models import User from rest_framework import serializers class ReviewInputSerializer ( serializers . Serializer ): product_id = serializers . UUIDField () score = serializers . ChoiceField ( choices = [ 1 , 2 , 3 , 4 , 5 ]) review = serializers . CharField () user = serializers . SerializerMethodField () # Current request object is always included # in the serializer context def get_user ( self , obj ) -> User : return self . context [ \"request\" ] . user class ReviewOutputSerializer ( serializers . Serializer ): class RecommendationSerializer ( serializers . Serializer ): product_id = serializers . CharField () avg_score = serializers . FloatField () score = serializers . ChoiceField ( choices = [ 1 , 2 , 3 , 4 , 5 ]) review = serializers . CharField () recommendations = RecommendationSerializer ( many = True ) And now the main logic, the business logic services.py from uuid import UUID import requests from django.contrib.auth.models import User from .models import Product , Review class Recommencation ( TypedDict ): product_id : str avg_score : float def review_product ( product_id : UUID , score : int , review : str , user : User ): product = Product . objects . get ( product_id ) user_review = Review . objects . add_review ( product , user , score , review ) return { \"product\" : product , \"review\" : user_review } def get_recommendations ( product : Product , review : Review ): payload = { \"product\" : str ( product . id ), \"score\" : review . score } response = requests . get ( \"...\" , params = payload ) data : list [ Recommencation ] = response . json () return { \"score\" : review . score , \"review\" : review . content , \"recommendations\" : data } Finally, let's put those together in the pipeline. views.py from pipeline_views import BasePipelineView from .serializers import ReviewInputSerializer , ReviewOutputSerializer from .services import review_product , get_recommendations class SomeView ( BasePipelineView ): pipelines = { \"POST\" : [ ReviewInputSerializer , add_review_for_product , get_recommendations , ReviewOutputSerializer , ], } A Closer Look Notice that the output from the previous function is used as the input of for the next function. def review_product ( product_id : UUID , score : int , review : str , user : User ): product = Product . objects . get ( product_id ) user_review = Review . objects . add_review ( product , user , score , review ) return { \"product\" : product , \"review\" : user_review } def get_recommendations ( product : Product , review : Review ): payload = { \"product\" : str ( product . id ), \"score\" : review . score } response = requests . get ( \"...\" , params = payload ) data : list [ Recommencation ] = response . json () return { \"score\" : review . score , \"review\" : review . content , \"recommendations\" : data } Depending on your needs, you might want to reuse a logic fuction in a different context, and you might not always give the same input. You can make the functions more generic by specifying **kwargs . def review_product ( ** kwargs ): product_id : UUID = kwargs [ \"product_id\" ] score : int = kwargs [ \"score\" ] review : str = kwargs [ \"review\" ] user : User = kwargs [ \"user\" ] product = Product . objects . get ( product_id ) user_review = Review . objects . add_review ( product , user , score , review ) return { \"product\" : product , \"review\" : user_review } def get_recommendations ( ** kwargs ): product : Product = kwargs [ \"product\" ] review : Review = kwargs [ \"review\" ] payload = { \"product\" : str ( product . id ), \"score\" : review . score } response = requests . get ( \"...\" , params = payload ) data : list [ Recommencation ] = response . json () return { \"score\" : review . score , \"review\" : review . content , \"recommendations\" : data } You can even make functions that are only used to verify input, but do not modify the output at all (or only add data to it). def validate_data ( ** kwargs ): # Validation goes here. # Might raise an exception, # which interrupts the pipeline. return kwargs Another point no note is that the functions are easily testable. review_product can be tested without mocking the GET request to the outside system, get_recommendations can be tested without making database queries. Some functions, like validators, have no side effects, which makes them easy and fast to unit test.","title":"Quickstart"},{"location":"quickstart/#quickstart","text":"","title":"Quickstart"},{"location":"quickstart/#example","text":"This will be a toy example, so the specific implementations details are not important here, rather the separation of logic. We are going to build a pipeline that takes product reviews from users, saves them to our database, contacts some outside system for recommendations based on the given review, and responds with the user's review and recommendation. It's a good idea to first define an InputSerializer, and an OutputSerializer that define the input and output of the pipeline respectively. This forces verification of the incoming and outcoming data, so that if something changes in the pipeline, or some unexpected values are produced, the endpoint will break instead of creating side effects in the application using the API. We'll also get better documentation in The Browsable API or any tool based on the OpenAPI specification, like Swagger. More about automatic documentation for pipeline views here . serializers.py from django.contrib.auth.models import User from rest_framework import serializers class ReviewInputSerializer ( serializers . Serializer ): product_id = serializers . UUIDField () score = serializers . ChoiceField ( choices = [ 1 , 2 , 3 , 4 , 5 ]) review = serializers . CharField () user = serializers . SerializerMethodField () # Current request object is always included # in the serializer context def get_user ( self , obj ) -> User : return self . context [ \"request\" ] . user class ReviewOutputSerializer ( serializers . Serializer ): class RecommendationSerializer ( serializers . Serializer ): product_id = serializers . CharField () avg_score = serializers . FloatField () score = serializers . ChoiceField ( choices = [ 1 , 2 , 3 , 4 , 5 ]) review = serializers . CharField () recommendations = RecommendationSerializer ( many = True ) And now the main logic, the business logic services.py from uuid import UUID import requests from django.contrib.auth.models import User from .models import Product , Review class Recommencation ( TypedDict ): product_id : str avg_score : float def review_product ( product_id : UUID , score : int , review : str , user : User ): product = Product . objects . get ( product_id ) user_review = Review . objects . add_review ( product , user , score , review ) return { \"product\" : product , \"review\" : user_review } def get_recommendations ( product : Product , review : Review ): payload = { \"product\" : str ( product . id ), \"score\" : review . score } response = requests . get ( \"...\" , params = payload ) data : list [ Recommencation ] = response . json () return { \"score\" : review . score , \"review\" : review . content , \"recommendations\" : data } Finally, let's put those together in the pipeline. views.py from pipeline_views import BasePipelineView from .serializers import ReviewInputSerializer , ReviewOutputSerializer from .services import review_product , get_recommendations class SomeView ( BasePipelineView ): pipelines = { \"POST\" : [ ReviewInputSerializer , add_review_for_product , get_recommendations , ReviewOutputSerializer , ], }","title":"Example"},{"location":"quickstart/#a-closer-look","text":"Notice that the output from the previous function is used as the input of for the next function. def review_product ( product_id : UUID , score : int , review : str , user : User ): product = Product . objects . get ( product_id ) user_review = Review . objects . add_review ( product , user , score , review ) return { \"product\" : product , \"review\" : user_review } def get_recommendations ( product : Product , review : Review ): payload = { \"product\" : str ( product . id ), \"score\" : review . score } response = requests . get ( \"...\" , params = payload ) data : list [ Recommencation ] = response . json () return { \"score\" : review . score , \"review\" : review . content , \"recommendations\" : data } Depending on your needs, you might want to reuse a logic fuction in a different context, and you might not always give the same input. You can make the functions more generic by specifying **kwargs . def review_product ( ** kwargs ): product_id : UUID = kwargs [ \"product_id\" ] score : int = kwargs [ \"score\" ] review : str = kwargs [ \"review\" ] user : User = kwargs [ \"user\" ] product = Product . objects . get ( product_id ) user_review = Review . objects . add_review ( product , user , score , review ) return { \"product\" : product , \"review\" : user_review } def get_recommendations ( ** kwargs ): product : Product = kwargs [ \"product\" ] review : Review = kwargs [ \"review\" ] payload = { \"product\" : str ( product . id ), \"score\" : review . score } response = requests . get ( \"...\" , params = payload ) data : list [ Recommencation ] = response . json () return { \"score\" : review . score , \"review\" : review . content , \"recommendations\" : data } You can even make functions that are only used to verify input, but do not modify the output at all (or only add data to it). def validate_data ( ** kwargs ): # Validation goes here. # Might raise an exception, # which interrupts the pipeline. return kwargs Another point no note is that the functions are easily testable. review_product can be tested without mocking the GET request to the outside system, get_recommendations can be tested without making database queries. Some functions, like validators, have no side effects, which makes them easy and fast to unit test.","title":"A Closer Look"},{"location":"schema/","text":"OpenAPI Schema Pipeline views support OpenAPI schema by default. Here is an example pipeline. from django.urls import path from rest_framework import serializers from pipeline_views.views import BasePipelineView from openapi_schema.views import get_schema_view class InputSerializer ( serializers . Serializer ): \"\"\"Example Input\"\"\" name = serializers . CharField ( help_text = \"foo\" ) age = serializers . IntegerField ( help_text = \"bar\" ) class OutputSerializer ( serializers . Serializer ): \"\"\"Example Output\"\"\" email = serializers . EmailField ( help_text = \"fizz\" ) age = serializers . IntegerField ( help_text = \"buzz\" ) def example_method ( name : str , age : int ): return { \"email\" : f \" { name . lower () } @email.com\" , \"age\" : age } class ExampleView ( BasePipelineView ): \"\"\"Example View\"\"\" pipelines = { \"POST\" : [ InputSerializer , example_method , OutputSerializer , ], } urlpatterns = [ path ( \"example\" , ExampleView . as_view (), name = \"example\" ), path ( \"openapi/\" , get_schema_view ( title = \"Your Project\" , root_url = \"api/v1/\" , description = \"API for all things\" , version = \"1.0.0\" , contact = { \"email\" : \"user@example.com\" }, license = { \"name\" : \"MIT\" }, terms_of_service = \"example.com\" , ), name = \"openapi-schema\" , ), ] This gets converted to the following OpenAPI schema. openapi openapi : 3.0.2 info : title : Your Project version : 1.0.0 description : API for all things contact : email : user@example.com license : name : MIT termsOfService : example.com paths : /example/ : post : operationId : createInput description : Example Input parameters : [] requestBody : content : application/json : schema : $ref : '#/components/schemas/Input' application/x-www-form-urlencoded : schema : $ref : '#/components/schemas/Input' multipart/form-data : schema : $ref : '#/components/schemas/Input' responses : '200' : content : application/json : schema : $ref : '#/components/schemas/Output' description : Example Output tags : - example components : schemas : Input : type : object properties : name : type : string description : foo age : type : integer description : bar required : - name - age Output : type : object properties : email : type : string format : email description : fizz age : type : integer description : buzz required : - email - age Additional responses You can add additional responses in the initialization of the schema. from rest_framework import serializers from pipeline_views.views import BasePipelineView from openapi_schema.schema import PipelineSchema class ErrorSerializer ( serializers . Serializer ): \"\"\"This is a custom error\"\"\" loc = serializers . ListField ( child = serializers . CharField ()) msg = serializers . CharField () type = serializers . CharField () class ExampleView ( BasePipelineView ): \"\"\"Example View\"\"\" pipelines = { \"POST\" : [ ... ], } schema = PipelineSchema ( responses = { \"POST\" : { 400 : ErrorSerializer , 404 : \"This is the error message\" } } ) openapi # ... paths : /example/ : post : # ... responses : # ... '400' : content : application/json : schema : $ref : '#/components/schemas/Error' description : This is a custom error '404' : content : application/json : schema : type : object properties : detail : type : string default : error message description : This is the error message components : schemas : # ... Error : type : object properties : loc : type : array items : type : string msg : type : string type : type : string required : - loc - msg - type In case your pipeline returns a list response, a default 204 response will be added automatically. Dynamic responses You can also define dynamic responses with the help of MockSerializer. from openapi_schema.schema import PipelineSchema from pipeline_views.views import BasePipelineView from serializer_inference.serializers import MockSerializer class ExampleView ( BasePipelineView ): \"\"\"Example View\"\"\" pipelines = { \"POST\" : [ ... ], } schema = PipelineSchema ( responses = { \"POST\" : { 404 : MockSerializer . with_example ( description = \"This is the error message\" , response = { \" {date} \" : { \" {time} \" : [ \"'free' or 'not free'\" , ], }, }, ) } } ) openapi # ... paths : /example : post : # ... responses : # ... '404' : content : application/json : schema : type : object properties : '{date}' : type : object properties : '{time}' : type : array items : type : string default : ' '' free '' or '' not free '' ' description : This is the error message # ... Deprecation You can deprecate endpoints on a method by method basis. from pipeline_views.views import BasePipelineView from openapi_schema.schema import PipelineSchema class ExampleView ( BasePipelineView ): \"\"\"Example View\"\"\" pipelines = { \"POST\" : [ ... ], } schema = PipelineSchema ( deprecated = [ \"POST\" ], ) You can also use the pipeline_views.schema.deprecate on the view. from pipeline_views.views import BasePipelineView from openapi_schema.utils import deprecate @deprecate ( methods = [ \"POST\" ]) class ExampleView ( BasePipelineView ): \"\"\"Example View\"\"\" pipelines = { \"POST\" : [ ... ], } You can deprecate all methods by omitting the methods argument. Security schemes Add security schemes to the endpoints. from pipeline_views.views import BasePipelineView from openapi_schema.schema import PipelineSchema class ExampleView ( BasePipelineView ): \"\"\"Example View\"\"\" pipelines = { \"POST\" : [ ... ], } schema = PipelineSchema ( security = { \"POST\" : { \"my_security\" : [], }, }, ) The value for the security scheme defines its scopes . The security scheme also needs to be added to the schema view. You can do this by adding the following: from django.urls import path from openapi_schema.views import get_schema_view urlpatterns = [ path ( \"example/\" , ExampleView . as_view (), name = \"test_view\" ), path ( \"openapi/\" , get_schema_view ( title = \"Your Project\" , description = \"API for all things\" , version = \"1.0.0\" , security_schemes = { \"my_security\" : { \"type\" : \"http\" , \"scheme\" : \"bearer\" , \"bearerFormat\" : \"JWT\" , }, }, ), name = \"openapi-schema\" , ), ] openapi # ... components : # ... securitySchemes : my_security : type : http scheme : bearer bearerFormat : JWT # ... Automatic security schemes You can also define rules that will automatically add certain security schemes to views based on their authentication and permission classes. The key for the security rules is either a single authentication and permission class, or a tuple of them. If the view already has any of the schemas defined for it, the view's configuration will take precedence. from django.urls import path from rest_framework.permissions import IsAuthenticated from openapi_schema.views import get_schema_view from pipeline_views.views import BasePipelineView class ExampleView ( BasePipelineView ): \"\"\"Example View\"\"\" permission_classes = [ IsAuthenticated ] pipelines = { \"POST\" : [ ... ], } urlpatterns = [ path ( \"example/\" , ExampleView . as_view (), name = \"test_view\" ), path ( \"openapi/\" , get_schema_view ( title = \"Your Project\" , description = \"API for all things\" , version = \"1.0.0\" , security_schemes = { \"my_security\" : { \"type\" : \"http\" , \"scheme\" : \"bearer\" , \"bearerFormat\" : \"JWT\" , }, }, security_rules = { IsAuthenticated : { \"my_security\" : [], }, }, ), name = \"openapi-schema\" , ), ] openapi # ... paths : /example : post : # ... security : - my_security : [] components : # ... securitySchemes : my_security : type : http scheme : bearer bearerFormat : JWT # ... Query, path, header, and cookie parameters For pipelines using the GET method, input serializer fields are interpreted automatically as query parameters. If the endpoint has path parameters, those are used in the schema instead, but with the documentation from the input serializer. For other HTTP methods, you need to explicitly state that if a value is given as a parameter instead of in the request body. This is just for schema definition, the endpoints will actually accept the input from both places. from pipeline_views.views import BasePipelineView from openapi_schema.schema import PipelineSchema class ExampleView ( BasePipelineView ): \"\"\"Example View\"\"\" pipelines = { \"POST\" : [ ... ], } schema = PipelineSchema ( query_parameters = { \"POST\" : [ \"name\" ], }, ) You can also declare a parameter as a header or as cookie parameter. from pipeline_views.views import BasePipelineView from openapi_schema.schema import PipelineSchema class ExampleView ( BasePipelineView ): \"\"\"Example View\"\"\" pipelines = { \"POST\" : [ ... ], } schema = PipelineSchema ( header_parameters = { \"POST\" : [ \"name\" ], }, cookie_parameters = { \"POST\" : [ \"name\" ], }, ) However, you'll need to handle getting the parameter from cookies in the input serializer separately. You can use HeaderAndCookieSerializer for this. This will ass fields to the serializer to accept the defined headers and cookies from the incoming request as strings, or None if they were not given. from pipeline_views.serializers import HeaderAndCookieSerializer class TestSerialzer ( HeaderAndCookieSerializer ): take_from_headers = [ \"foo\" ] take_from_cookies = [ \"bar\" ] External docs External docs for an endpoint can also be added. from pipeline_views.views import BasePipelineView from openapi_schema.schema import PipelineSchema class ExampleView ( BasePipelineView ): \"\"\"Example View\"\"\" pipelines = { \"POST\" : [ ... ], } schema = PipelineSchema ( external_docs = { \"POST\" : { \"description\" : \"Look here for more information\" , \"url\" : \"...\" , }, }, ) Public Endpoints can be set public/private for the whole API (public by default). Private endpoints are not visible to users that do not have the appropriate permissions. from django.urls import path from openapi_schema.views import get_schema_view urlpatterns = [ path ( \"example/\" , ExampleView . as_view (), name = \"test_view\" ), path ( \"openapi/\" , get_schema_view ( title = \"Your Project\" , description = \"API for all things\" , version = \"1.0.0\" , public = False , ), name = \"openapi-schema\" , ), ] You can also set individual endpoints public/private. This will override the API-wide configuration. from pipeline_views.views import BasePipelineView from openapi_schema.schema import PipelineSchema class ExampleView ( BasePipelineView ): \"\"\"Example View\"\"\" pipelines = { \"POST\" : [ ... ], } schema = PipelineSchema ( public = { \"POST\" : False , }, ) Links Using links , you can describe how various values returned by one operation can be used as input for other operations. from pipeline_views import BasePipelineView from openapi_schema.schema import PipelineSchema class ExampleView ( BasePipelineView ): \"\"\"Example View\"\"\" pipelines = { \"POST\" : [ ... ], } schema = PipelineSchema ( links = { \"POST\" : { 200 : { \"LinkTitle\" : { \"description\" : \"Description\" , \"operationId\" : \"partialUpdateInput\" , \"parameters\" : { \"age\" : \"$request.body#/age\" , }, } }, }, }, ) # ... paths : /example/ : post : # ... responses : '200' : # ... links : LinkTitle : description : Description operationId : partialUpdateInput parameters : age : $request.body#/age # ... Callbacks Callbacks are asynchronous, out-of-band requests that your service will send to some other service in response to certain events. from rest_framework import serializers from pipeline_views import BasePipelineView from openapi_schema.schema import PipelineSchema class InputSerializer ( serializers . Serializer ): \"\"\"Example Input\"\"\" name = serializers . CharField () age = serializers . IntegerField () class OutputSerializer ( serializers . Serializer ): \"\"\"Example Output\"\"\" email = serializers . EmailField () age = serializers . IntegerField () class ExampleView ( BasePipelineView ): \"\"\"Example View\"\"\" pipelines = { \"POST\" : [ ... ], } schema = PipelineSchema ( callbacks = { \"EventName\" : { \"CallbackUrl\" : { \"POST\" : { \"request_body\" : InputSerializer , \"responses\" : { 200 : OutputSerializer , }, }, }, }, }, ) # ... paths : /example/ : post : # ... callbacks : EventName : CallbackUrl : post : requestBody : content : application/json : schema : type : object properties : name : type : string age : type : integer required : - name - age responses : 200 : content : application/json : schema : type : object properties : email : type : string format : email age : type : integer required : - email - age # ... Webhooks Webhooks describe requests initiated other than by an API call, for example by an out-of-band registration. You can define them in the PipelineSchemaGenerator. from django.urls import path from rest_framework import serializers from openapi_schema.views import get_schema_view class InputSerializer ( serializers . Serializer ): \"\"\"Example Input\"\"\" name = serializers . CharField () age = serializers . IntegerField () class OutputSerializer ( serializers . Serializer ): \"\"\"Example Output\"\"\" email = serializers . EmailField () age = serializers . IntegerField () urlpatterns = [ path ( \"openapi/\" , get_schema_view ( title = \"Your Project\" , description = \"API for all things\" , version = \"1.0.0\" , webhooks = { \"ExampleWebhook\" : { \"method\" : \"POST\" , \"request_data\" : InputSerializer , \"responses\" : { 200 : OutputSerializer , 400 : \"Failure\" , }, }, }, ), name = \"openapi-schema\" , ), ] # ... webhooks : ExampleWebhook : POST : requestBody : description : Example Input content : application/json : schema : type : object properties : name : type : string age : type : integer required : - name - age responses : '200' : description : Example Output content : application/json : type : object properties : email : type : string format : email age : type : integer required : - email - age '400' : description : Failure # ...","title":"OpenAPI Schema"},{"location":"schema/#openapi-schema","text":"Pipeline views support OpenAPI schema by default. Here is an example pipeline. from django.urls import path from rest_framework import serializers from pipeline_views.views import BasePipelineView from openapi_schema.views import get_schema_view class InputSerializer ( serializers . Serializer ): \"\"\"Example Input\"\"\" name = serializers . CharField ( help_text = \"foo\" ) age = serializers . IntegerField ( help_text = \"bar\" ) class OutputSerializer ( serializers . Serializer ): \"\"\"Example Output\"\"\" email = serializers . EmailField ( help_text = \"fizz\" ) age = serializers . IntegerField ( help_text = \"buzz\" ) def example_method ( name : str , age : int ): return { \"email\" : f \" { name . lower () } @email.com\" , \"age\" : age } class ExampleView ( BasePipelineView ): \"\"\"Example View\"\"\" pipelines = { \"POST\" : [ InputSerializer , example_method , OutputSerializer , ], } urlpatterns = [ path ( \"example\" , ExampleView . as_view (), name = \"example\" ), path ( \"openapi/\" , get_schema_view ( title = \"Your Project\" , root_url = \"api/v1/\" , description = \"API for all things\" , version = \"1.0.0\" , contact = { \"email\" : \"user@example.com\" }, license = { \"name\" : \"MIT\" }, terms_of_service = \"example.com\" , ), name = \"openapi-schema\" , ), ] This gets converted to the following OpenAPI schema. openapi openapi : 3.0.2 info : title : Your Project version : 1.0.0 description : API for all things contact : email : user@example.com license : name : MIT termsOfService : example.com paths : /example/ : post : operationId : createInput description : Example Input parameters : [] requestBody : content : application/json : schema : $ref : '#/components/schemas/Input' application/x-www-form-urlencoded : schema : $ref : '#/components/schemas/Input' multipart/form-data : schema : $ref : '#/components/schemas/Input' responses : '200' : content : application/json : schema : $ref : '#/components/schemas/Output' description : Example Output tags : - example components : schemas : Input : type : object properties : name : type : string description : foo age : type : integer description : bar required : - name - age Output : type : object properties : email : type : string format : email description : fizz age : type : integer description : buzz required : - email - age","title":"OpenAPI Schema"},{"location":"schema/#additional-responses","text":"You can add additional responses in the initialization of the schema. from rest_framework import serializers from pipeline_views.views import BasePipelineView from openapi_schema.schema import PipelineSchema class ErrorSerializer ( serializers . Serializer ): \"\"\"This is a custom error\"\"\" loc = serializers . ListField ( child = serializers . CharField ()) msg = serializers . CharField () type = serializers . CharField () class ExampleView ( BasePipelineView ): \"\"\"Example View\"\"\" pipelines = { \"POST\" : [ ... ], } schema = PipelineSchema ( responses = { \"POST\" : { 400 : ErrorSerializer , 404 : \"This is the error message\" } } ) openapi # ... paths : /example/ : post : # ... responses : # ... '400' : content : application/json : schema : $ref : '#/components/schemas/Error' description : This is a custom error '404' : content : application/json : schema : type : object properties : detail : type : string default : error message description : This is the error message components : schemas : # ... Error : type : object properties : loc : type : array items : type : string msg : type : string type : type : string required : - loc - msg - type In case your pipeline returns a list response, a default 204 response will be added automatically.","title":"Additional responses"},{"location":"schema/#dynamic-responses","text":"You can also define dynamic responses with the help of MockSerializer. from openapi_schema.schema import PipelineSchema from pipeline_views.views import BasePipelineView from serializer_inference.serializers import MockSerializer class ExampleView ( BasePipelineView ): \"\"\"Example View\"\"\" pipelines = { \"POST\" : [ ... ], } schema = PipelineSchema ( responses = { \"POST\" : { 404 : MockSerializer . with_example ( description = \"This is the error message\" , response = { \" {date} \" : { \" {time} \" : [ \"'free' or 'not free'\" , ], }, }, ) } } ) openapi # ... paths : /example : post : # ... responses : # ... '404' : content : application/json : schema : type : object properties : '{date}' : type : object properties : '{time}' : type : array items : type : string default : ' '' free '' or '' not free '' ' description : This is the error message # ...","title":"Dynamic responses"},{"location":"schema/#deprecation","text":"You can deprecate endpoints on a method by method basis. from pipeline_views.views import BasePipelineView from openapi_schema.schema import PipelineSchema class ExampleView ( BasePipelineView ): \"\"\"Example View\"\"\" pipelines = { \"POST\" : [ ... ], } schema = PipelineSchema ( deprecated = [ \"POST\" ], ) You can also use the pipeline_views.schema.deprecate on the view. from pipeline_views.views import BasePipelineView from openapi_schema.utils import deprecate @deprecate ( methods = [ \"POST\" ]) class ExampleView ( BasePipelineView ): \"\"\"Example View\"\"\" pipelines = { \"POST\" : [ ... ], } You can deprecate all methods by omitting the methods argument.","title":"Deprecation"},{"location":"schema/#security-schemes","text":"Add security schemes to the endpoints. from pipeline_views.views import BasePipelineView from openapi_schema.schema import PipelineSchema class ExampleView ( BasePipelineView ): \"\"\"Example View\"\"\" pipelines = { \"POST\" : [ ... ], } schema = PipelineSchema ( security = { \"POST\" : { \"my_security\" : [], }, }, ) The value for the security scheme defines its scopes . The security scheme also needs to be added to the schema view. You can do this by adding the following: from django.urls import path from openapi_schema.views import get_schema_view urlpatterns = [ path ( \"example/\" , ExampleView . as_view (), name = \"test_view\" ), path ( \"openapi/\" , get_schema_view ( title = \"Your Project\" , description = \"API for all things\" , version = \"1.0.0\" , security_schemes = { \"my_security\" : { \"type\" : \"http\" , \"scheme\" : \"bearer\" , \"bearerFormat\" : \"JWT\" , }, }, ), name = \"openapi-schema\" , ), ] openapi # ... components : # ... securitySchemes : my_security : type : http scheme : bearer bearerFormat : JWT # ...","title":"Security schemes"},{"location":"schema/#automatic-security-schemes","text":"You can also define rules that will automatically add certain security schemes to views based on their authentication and permission classes. The key for the security rules is either a single authentication and permission class, or a tuple of them. If the view already has any of the schemas defined for it, the view's configuration will take precedence. from django.urls import path from rest_framework.permissions import IsAuthenticated from openapi_schema.views import get_schema_view from pipeline_views.views import BasePipelineView class ExampleView ( BasePipelineView ): \"\"\"Example View\"\"\" permission_classes = [ IsAuthenticated ] pipelines = { \"POST\" : [ ... ], } urlpatterns = [ path ( \"example/\" , ExampleView . as_view (), name = \"test_view\" ), path ( \"openapi/\" , get_schema_view ( title = \"Your Project\" , description = \"API for all things\" , version = \"1.0.0\" , security_schemes = { \"my_security\" : { \"type\" : \"http\" , \"scheme\" : \"bearer\" , \"bearerFormat\" : \"JWT\" , }, }, security_rules = { IsAuthenticated : { \"my_security\" : [], }, }, ), name = \"openapi-schema\" , ), ] openapi # ... paths : /example : post : # ... security : - my_security : [] components : # ... securitySchemes : my_security : type : http scheme : bearer bearerFormat : JWT # ...","title":"Automatic security schemes"},{"location":"schema/#query-path-header-and-cookie-parameters","text":"For pipelines using the GET method, input serializer fields are interpreted automatically as query parameters. If the endpoint has path parameters, those are used in the schema instead, but with the documentation from the input serializer. For other HTTP methods, you need to explicitly state that if a value is given as a parameter instead of in the request body. This is just for schema definition, the endpoints will actually accept the input from both places. from pipeline_views.views import BasePipelineView from openapi_schema.schema import PipelineSchema class ExampleView ( BasePipelineView ): \"\"\"Example View\"\"\" pipelines = { \"POST\" : [ ... ], } schema = PipelineSchema ( query_parameters = { \"POST\" : [ \"name\" ], }, ) You can also declare a parameter as a header or as cookie parameter. from pipeline_views.views import BasePipelineView from openapi_schema.schema import PipelineSchema class ExampleView ( BasePipelineView ): \"\"\"Example View\"\"\" pipelines = { \"POST\" : [ ... ], } schema = PipelineSchema ( header_parameters = { \"POST\" : [ \"name\" ], }, cookie_parameters = { \"POST\" : [ \"name\" ], }, ) However, you'll need to handle getting the parameter from cookies in the input serializer separately. You can use HeaderAndCookieSerializer for this. This will ass fields to the serializer to accept the defined headers and cookies from the incoming request as strings, or None if they were not given. from pipeline_views.serializers import HeaderAndCookieSerializer class TestSerialzer ( HeaderAndCookieSerializer ): take_from_headers = [ \"foo\" ] take_from_cookies = [ \"bar\" ]","title":"Query, path, header, and cookie parameters"},{"location":"schema/#external-docs","text":"External docs for an endpoint can also be added. from pipeline_views.views import BasePipelineView from openapi_schema.schema import PipelineSchema class ExampleView ( BasePipelineView ): \"\"\"Example View\"\"\" pipelines = { \"POST\" : [ ... ], } schema = PipelineSchema ( external_docs = { \"POST\" : { \"description\" : \"Look here for more information\" , \"url\" : \"...\" , }, }, )","title":"External docs"},{"location":"schema/#public","text":"Endpoints can be set public/private for the whole API (public by default). Private endpoints are not visible to users that do not have the appropriate permissions. from django.urls import path from openapi_schema.views import get_schema_view urlpatterns = [ path ( \"example/\" , ExampleView . as_view (), name = \"test_view\" ), path ( \"openapi/\" , get_schema_view ( title = \"Your Project\" , description = \"API for all things\" , version = \"1.0.0\" , public = False , ), name = \"openapi-schema\" , ), ] You can also set individual endpoints public/private. This will override the API-wide configuration. from pipeline_views.views import BasePipelineView from openapi_schema.schema import PipelineSchema class ExampleView ( BasePipelineView ): \"\"\"Example View\"\"\" pipelines = { \"POST\" : [ ... ], } schema = PipelineSchema ( public = { \"POST\" : False , }, )","title":"Public"},{"location":"schema/#links","text":"Using links , you can describe how various values returned by one operation can be used as input for other operations. from pipeline_views import BasePipelineView from openapi_schema.schema import PipelineSchema class ExampleView ( BasePipelineView ): \"\"\"Example View\"\"\" pipelines = { \"POST\" : [ ... ], } schema = PipelineSchema ( links = { \"POST\" : { 200 : { \"LinkTitle\" : { \"description\" : \"Description\" , \"operationId\" : \"partialUpdateInput\" , \"parameters\" : { \"age\" : \"$request.body#/age\" , }, } }, }, }, ) # ... paths : /example/ : post : # ... responses : '200' : # ... links : LinkTitle : description : Description operationId : partialUpdateInput parameters : age : $request.body#/age # ...","title":"Links"},{"location":"schema/#callbacks","text":"Callbacks are asynchronous, out-of-band requests that your service will send to some other service in response to certain events. from rest_framework import serializers from pipeline_views import BasePipelineView from openapi_schema.schema import PipelineSchema class InputSerializer ( serializers . Serializer ): \"\"\"Example Input\"\"\" name = serializers . CharField () age = serializers . IntegerField () class OutputSerializer ( serializers . Serializer ): \"\"\"Example Output\"\"\" email = serializers . EmailField () age = serializers . IntegerField () class ExampleView ( BasePipelineView ): \"\"\"Example View\"\"\" pipelines = { \"POST\" : [ ... ], } schema = PipelineSchema ( callbacks = { \"EventName\" : { \"CallbackUrl\" : { \"POST\" : { \"request_body\" : InputSerializer , \"responses\" : { 200 : OutputSerializer , }, }, }, }, }, ) # ... paths : /example/ : post : # ... callbacks : EventName : CallbackUrl : post : requestBody : content : application/json : schema : type : object properties : name : type : string age : type : integer required : - name - age responses : 200 : content : application/json : schema : type : object properties : email : type : string format : email age : type : integer required : - email - age # ...","title":"Callbacks"},{"location":"schema/#webhooks","text":"Webhooks describe requests initiated other than by an API call, for example by an out-of-band registration. You can define them in the PipelineSchemaGenerator. from django.urls import path from rest_framework import serializers from openapi_schema.views import get_schema_view class InputSerializer ( serializers . Serializer ): \"\"\"Example Input\"\"\" name = serializers . CharField () age = serializers . IntegerField () class OutputSerializer ( serializers . Serializer ): \"\"\"Example Output\"\"\" email = serializers . EmailField () age = serializers . IntegerField () urlpatterns = [ path ( \"openapi/\" , get_schema_view ( title = \"Your Project\" , description = \"API for all things\" , version = \"1.0.0\" , webhooks = { \"ExampleWebhook\" : { \"method\" : \"POST\" , \"request_data\" : InputSerializer , \"responses\" : { 200 : OutputSerializer , 400 : \"Failure\" , }, }, }, ), name = \"openapi-schema\" , ), ] # ... webhooks : ExampleWebhook : POST : requestBody : description : Example Input content : application/json : schema : type : object properties : name : type : string age : type : integer required : - name - age responses : '200' : description : Example Output content : application/json : type : object properties : email : type : string format : email age : type : integer required : - email - age '400' : description : Failure # ...","title":"Webhooks"}]}